{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459ed8f6",
   "metadata": {},
   "source": [
    "# SHAP Explainability Layer\\nImplementation of feature-level explanations for the Hybrid Credit Scoring pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "191e6424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete. SHAP version: 0.49.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import joblib\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Setup complete. SHAP version:\", shap.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de1fdc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models and background data loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load Models\n",
    "pd_model = joblib.load('pd_model.joblib')\n",
    "pd_scaler = joblib.load('pd_scaler.joblib')\n",
    "pd_features = joblib.load('pd_features.joblib')\n",
    "\n",
    "iso_model = joblib.load('isolation_forest.joblib')\n",
    "if_scaler = joblib.load('if_scaler.joblib')\n",
    "# isolation forest features were: [\"avgMonthlyIncome\", \"incomeCV\", \"expenseRatio\", \"emiRatio\", \"avgMonthlyBalance\", \"bounceCount\"]\n",
    "if_features = [\"avgMonthlyIncome\", \"incomeCV\", \"expenseRatio\", \"emiRatio\", \"avgMonthlyBalance\", \"bounceCount\"]\n",
    "\n",
    "risk_model = joblib.load('risk_random_forest.joblib')\n",
    "risk_features = joblib.load('risk_features.joblib')\n",
    "\n",
    "# Load background data for SHAP initialization\n",
    "# We use the synthetic feature files as background reference\n",
    "bg_data = pd.read_csv('../data/synthetic/features_only.csv')\n",
    "\n",
    "print(\"✅ Models and background data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6a9373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SHAP Explainers initialized.\n"
     ]
    }
   ],
   "source": [
    "# 1. PD Model Explainer (Linear)\n",
    "# We use a sample of background data to initialize the explainer\n",
    "X_pd_bg = pd_scaler.transform(bg_data[pd_features])\n",
    "pd_explainer = shap.LinearExplainer(pd_model, X_pd_bg)\n",
    "\n",
    "# 2. Anomaly Model Explainer (Tree)\n",
    "# Isolation Forest is supported by TreeExplainer\n",
    "if_explainer = shap.TreeExplainer(iso_model)\n",
    "\n",
    "# 3. Risk Label Model Explainer (Tree)\n",
    "# Background data for Risk Model includes PD and anomalyFlag\n",
    "# For simplicity in this demo, we'll use a sample from the predictions file\n",
    "risk_df = pd.read_csv('../data/synthetic/features_with_risk_predictions.csv')\n",
    "X_risk_bg = risk_df[risk_features]\n",
    "risk_explainer = shap.TreeExplainer(risk_model)\n",
    "\n",
    "print(\"✅ SHAP Explainers initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8def1ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Explanation Aggregator defined.\n"
     ]
    }
   ],
   "source": [
    "def get_explanation_aggregator(input_row):\n",
    "    \"\"\"\n",
    "    Generates human-readable explanations from SHAP values for a single input row (dict).\n",
    "    \"\"\"\n",
    "    # 1. Prepare Data\n",
    "    df_input = pd.DataFrame([input_row])\n",
    "    \n",
    "    # 2. PD Explanation\n",
    "    X_pd = pd_scaler.transform(df_input[pd_features])\n",
    "    pd_val = pd_model.predict_proba(X_pd)[0, 1]\n",
    "    pd_shap_values = pd_explainer.shap_values(X_pd)\n",
    "    # top 3 factors\n",
    "    pd_indices = np.argsort(np.abs(pd_shap_values[0]))[::-1][:3]\n",
    "    pd_top_factors = [pd_features[i] for i in pd_indices]\n",
    "\n",
    "    # 3. Anomaly Explanation\n",
    "    X_if = if_scaler.transform(df_input[if_features])\n",
    "    if_score = iso_model.decision_function(X_if)[0]\n",
    "    if_shap_values = if_explainer.shap_values(X_if)\n",
    "    # TreeExplainer for IF returns a single array\n",
    "    if isinstance(if_shap_values, list):\n",
    "        if_shap = if_shap_values[0]\n",
    "    else:\n",
    "        if_shap = if_shap_values\n",
    "\n",
    "    if_indices = np.argsort(np.abs(if_shap[0]))[::-1][:2]\n",
    "    if_reasons = [if_features[i] for i in if_indices]\n",
    "\n",
    "    # 4. Risk Label Explanation\n",
    "    # Prepare risk features by including simulation results for PD and Anomaly\n",
    "    X_risk_prep = df_input.copy()\n",
    "    X_risk_prep['PD'] = pd_val\n",
    "    X_risk_prep['anomalyFlag'] = 1 if if_score < -0.05 else 0 \n",
    "    \n",
    "    # Select features in the correct order for the Risk model\n",
    "    X_risk = X_risk_prep[risk_features]\n",
    "    \n",
    "    risk_label_idx = int(risk_model.predict(X_risk)[0])\n",
    "    risk_labels = [\"LOW\", \"MEDIUM\", \"HIGH\"]\n",
    "    risk_label = risk_labels[risk_label_idx]\n",
    "    \n",
    "    risk_shap_values = risk_explainer.shap_values(X_risk)\n",
    "    # TreeExplainer for Multi-class returns a list of arrays. Index corresponds to class.\n",
    "    if isinstance(risk_shap_values, list):\n",
    "        class_shap = risk_shap_values[risk_label_idx]\n",
    "    else:\n",
    "        # Some versions return a 3D array\n",
    "        class_shap = risk_shap_values[:,:,risk_label_idx] if risk_shap_values.ndim == 3 else risk_shap_values\n",
    "    \n",
    "    risk_indices = np.argsort(np.abs(class_shap[0]))[::-1][:3]\n",
    "    risk_drivers = [risk_features[i] for i in risk_indices]\n",
    "\n",
    "    # 5. Aggregate\n",
    "    response = {\n",
    "        \"PD\": {\n",
    "            \"value\": round(float(pd_val), 4),\n",
    "            \"top_factors\": pd_top_factors\n",
    "        },\n",
    "        \"Anomaly\": {\n",
    "            \"score\": round(float(if_score), 4),\n",
    "            \"reasons\": if_reasons\n",
    "        },\n",
    "        \"RiskLabel\": {\n",
    "            \"label\": risk_label,\n",
    "            \"drivers\": risk_drivers\n",
    "        }\n",
    "    }\n",
    "    return response\n",
    "\n",
    "print(\"✅ Explanation Aggregator defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b9c06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Unified Explanation Response ---\n",
      "{\n",
      "  \"PD\": {\n",
      "    \"value\": 0.0003,\n",
      "    \"top_factors\": [\n",
      "      \"expenseRatio\",\n",
      "      \"accountAgeMonths\",\n",
      "      \"emiRatio\"\n",
      "    ]\n",
      "  },\n",
      "  \"Anomaly\": {\n",
      "    \"score\": 0.1592,\n",
      "    \"reasons\": [\n",
      "      \"expenseRatio\",\n",
      "      \"bounceCount\"\n",
      "    ]\n",
      "  },\n",
      "  \"RiskLabel\": {\n",
      "    \"label\": \"LOW\",\n",
      "    \"drivers\": [\n",
      "      \"PD\",\n",
      "      \"expenseRatio\",\n",
      "      \"emiRatio\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test Case: Sample Customer\n",
    "test_customer = {\n",
    "    'avgMonthlyIncome': 75000,\n",
    "    'incomeCV': 0.1,\n",
    "    'expenseRatio': 0.3,\n",
    "    'emiRatio': 0.2,\n",
    "    'avgMonthlyBalance': 50000,\n",
    "    'bounceCount': 0,\n",
    "    'accountAgeMonths': 24\n",
    "}\n",
    "\n",
    "explanation = get_explanation_aggregator(test_customer)\n",
    "print(\"\\n--- Unified Explanation Response ---\")\n",
    "print(json.dumps(explanation, indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
