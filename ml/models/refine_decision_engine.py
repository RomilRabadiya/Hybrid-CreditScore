import json
import os

path = '/Users/romiljitendrabhai/Desktop/Hybrid Credit Score/ml/models/CreditDecisionEngine.ipynb'

cells = [
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": ["# Credit Decision Engine (Unified SHAP Architecture)\n", "A production-grade decision layer with feature-level explainability across all model layers."]
    },
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "import pandas as pd\n",
            "import numpy as np\n",
            "import shap\n",
            "import joblib\n",
            "import json\n",
            "import warnings\n",
            "from collections import defaultdict\n",
            "\n",
            "warnings.filterwarnings('ignore')\n",
            "print('✅ Architecture Phase 1: Dependencies loaded.')"
        ]
    },
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Phase 2 & 3: Load Artifacts and Prepare Background Data\n",
            "pd_model = joblib.load('pd_model.joblib')\n",
            "pd_scaler = joblib.load('pd_scaler.joblib')\n",
            "pd_features = joblib.load('pd_features.joblib')\n",
            "\n",
            "iso_model = joblib.load('isolation_forest.joblib')\n",
            "if_scaler = joblib.load('if_scaler.joblib')\n",
            "if_features = ['avgMonthlyIncome', 'incomeCV', 'expenseRatio', 'emiRatio', 'avgMonthlyBalance', 'bounceCount']\n",
            "\n",
            "risk_model = joblib.load('risk_random_forest.joblib')\n",
            "risk_features = joblib.load('risk_features.joblib')\n",
            "\n",
            "hybrid_model = joblib.load('hybrid_credit_score_model.joblib')\n",
            "hybrid_features = joblib.load('hybrid_features.joblib')\n",
            "\n",
            "q_table = joblib.load('q_learning_model.joblib')\n",
            "q_bins = joblib.load('q_learning_bins.joblib')\n",
            "q_features = joblib.load('q_learning_features.joblib')\n",
            "\n",
            "bg_data = pd.read_csv('../data/synthetic/features_only.csv')\n",
            "\n",
            "X_pd_bg = pd_scaler.transform(bg_data[pd_features])\n",
            "X_if_bg = if_scaler.transform(bg_data[if_features])\n",
            "X_risk_bg = bg_data[risk_features]\n",
            "X_hybrid_bg = bg_data[hybrid_features]\n",
            "\n",
            "print('✅ Architecture Phase 2 & 3: Background data prepared.')"
        ]
    },
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Phase 10: Business Language Mapping\n",
            "BUSINESS_MAPPING = {\n",
            "    \"avgMonthlyIncome\": \"Monthly Income Level\",\n",
            "    \"incomeCV\": \"Income Volatility\",\n",
            "    \"expenseRatio\": \"Monthly Expense Burden\",\n",
            "    \"emiRatio\": \"Existing Debt Commitments (EMI)\",\n",
            "    \"avgMonthlyBalance\": \"Liquidity Reserve\",\n",
            "    \"bounceCount\": \"Historical Payment Bounces\",\n",
            "    \"accountAgeMonths\": \"Banking Relationship Age\",\n",
            "    \"PD\": \"Probability of Default Signal\",\n",
            "    \"anomalyFlag\": \"Unusual Transaction Behavior\",\n",
            "    \"anomaly\": \"Anomaly Signal Intensity\",\n",
            "    \"HybridCreditScore\": \"Consolidated Credit Score\"\n",
            "}\n",
            "\n",
            "# Phase 3: Initialize Explainers (One-time at startup)\n",
            "pd_explainer = shap.LinearExplainer(pd_model, X_pd_bg)\n",
            "if_explainer = shap.TreeExplainer(iso_model)\n",
            "risk_explainer = shap.TreeExplainer(risk_model)\n",
            "hybrid_explainer = shap.Explainer(hybrid_model, X_hybrid_bg)\n",
            "\n",
            "def q_policy_func(X):\n",
            "    results = []\n",
            "    for row in X:\n",
            "        s = (np.digitize(row[0], q_bins['pd']),\n",
            "             np.digitize(row[1], q_bins['anom']),\n",
            "             np.digitize(row[2], q_bins['cs']))\n",
            "        q_vals = q_table.get(s, np.zeros(4))\n",
            "        results.append(np.max(q_vals))\n",
            "    return np.array(results)\n",
            "\n",
            "rl_bg = np.array([[0.1, 0.1, 600], [0.5, 0.5, 400], [0.1, 0.8, 400]])\n",
            "rl_explainer = shap.KernelExplainer(q_policy_func, rl_bg)\n",
            "\n",
            "print('✅ Architecture Phase 3: SHAP Explainers initialized.')"
        ]
    },
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Phase 4: Create Utility Function\n",
            "def top_shap_features(values, names, k=3):\n",
            "    idx = np.argsort(np.abs(values))[::-1][:k]\n",
            "    return [f\"{BUSINESS_MAPPING.get(names[i], names[i])} ({values[i]:+.3f})\" for i in idx]\n",
            "\n",
            "print('✅ Architecture Phase 4: Utility functions defined.')"
        ]
    },
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Phase 5, 6, & 7: Unified Pipeline with Conditional Explanation\n",
            "def get_decision_explanation(input_row, explain=True):\n",
            "    df_input = pd.DataFrame([input_row])\n",
            "    response = {}\n",
            "    \n",
            "    # 1. PD Layer\n",
            "    X_pd = pd_scaler.transform(df_input[pd_features])\n",
            "    pd_val = pd_model.predict_proba(X_pd)[0, 1]\n",
            "    response[\"PD\"] = {\"value\": round(float(pd_val), 4)}\n",
            "    \n",
            "    if explain:\n",
            "        pd_exp = pd_explainer(X_pd)\n",
            "        pd_shap_vals = pd_exp.values.flatten()\n",
            "        response[\"PD\"][\"top_factors\"] = top_shap_features(pd_shap_vals, pd_features)\n",
            "\n",
            "    # 2. Anomaly Layer\n",
            "    X_if = if_scaler.transform(df_input[if_features])\n",
            "    if_score = iso_model.decision_function(X_if)[0]\n",
            "    response[\"Anomaly\"] = {\"score\": round(float(if_score), 4)}\n",
            "    \n",
            "    if explain:\n",
            "        if_exp = if_explainer(X_if)\n",
            "        if_vals = if_exp.values.flatten()\n",
            "        response[\"Anomaly\"][\"top_factors\"] = top_shap_features(if_vals, if_features)\n",
            "\n",
            "    # 3. Risk Layer\n",
            "    df_risk = df_input.copy()\n",
            "    df_risk['PD'] = pd_val\n",
            "    df_risk['anomalyFlag'] = 1 if if_score < -0.05 else 0\n",
            "    X_risk = df_risk[risk_features]\n",
            "    risk_idx = int(risk_model.predict(X_risk)[0])\n",
            "    risk_label = [\"LOW\", \"MEDIUM\", \"HIGH\"][risk_idx]\n",
            "    response[\"RiskLabel\"] = {\"label\": risk_label}\n",
            "    \n",
            "    if explain:\n",
            "        risk_exp = risk_explainer(X_risk)\n",
            "        if risk_exp.values.ndim == 3: \n",
            "            risk_vals = risk_exp.values[0, :, risk_idx]\n",
            "        else:\n",
            "            risk_vals = risk_exp.values.flatten()\n",
            "        response[\"RiskLabel\"][\"drivers\"] = top_shap_features(risk_vals, risk_features)\n",
            "\n",
            "    # 4. Hybrid Score Layer\n",
            "    X_hyb = df_input[hybrid_features]\n",
            "    score_val = hybrid_model.predict(X_hyb)[0]\n",
            "    response[\"HybridScore\"] = {\"value\": round(float(score_val), 1)}\n",
            "    \n",
            "    if explain:\n",
            "        hyb_exp = hybrid_explainer(X_hyb)\n",
            "        hyb_vals = hyb_exp.values.flatten()\n",
            "        response[\"HybridScore\"][\"factors\"] = top_shap_features(hyb_vals, hybrid_features)\n",
            "\n",
            "    # 5. RL Action Layer (Recommended Policy)\n",
            "    anom_norm = np.clip(1.0 - (if_score + 0.5), 0, 1)\n",
            "    X_rl = np.array([[pd_val, anom_norm, score_val]])\n",
            "    s = (np.digitize(X_rl[0][0], q_bins['pd']),\n",
            "         np.digitize(X_rl[0][1], q_bins['anom']),\n",
            "         np.digitize(X_rl[0][2], q_bins['cs']))\n",
            "    \n",
            "    action_idx = int(np.argmax(q_table.get(s, np.zeros(4))))\n",
            "    actions = [\"REJECT\", \"APPROVE_LOW\", \"APPROVE_MEDIUM\", \"APPROVE_HIGH\"]\n",
            "    response[\"RL_Recommendation\"] = {\"action\": actions[action_idx]}\n",
            "    \n",
            "    if explain:\n",
            "        rl_exp = rl_explainer.shap_values(X_rl, silent=True)\n",
            "        rl_vals = rl_exp.flatten()\n",
            "        response[\"RL_Recommendation\"][\"rationales\"] = top_shap_features(rl_vals, q_features)\n",
            "\n",
            "    return response\n",
            "\n",
            "print('✅ Architecture Phase 5, 6, & 7: Unified Pipeline ready.')"
        ]
    },
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Phase 9: Validate SHAP Sanity\n",
            "elite_customer = {\n",
            "    'avgMonthlyIncome': 150000, 'incomeCV': 0.02, 'expenseRatio': 0.15, \n",
            "    'emiRatio': 0.05, 'avgMonthlyBalance': 100000, 'bounceCount': 0, 'accountAgeMonths': 60\n",
            "}\n",
            "\n",
            "risky_customer = {\n",
            "    'avgMonthlyIncome': 30000, 'incomeCV': 0.40, 'expenseRatio': 0.80, \n",
            "    'emiRatio': 0.60, 'avgMonthlyBalance': 500, 'bounceCount': 3, 'accountAgeMonths': 6\n",
            "}\n",
            "\n",
            "print('--- Elite Customer Explanation ---')\n",
            "print(json.dumps(get_decision_explanation(elite_customer), indent=2))\n",
            "\n",
            "print('\\n--- Risky Customer Explanation ---')\n",
            "print(json.dumps(get_decision_explanation(risky_customer), indent=2))"
        ]
    }
]

nb = {
    "cells": cells,
    "metadata": {"language_info": {"name": "python"}},
    "nbformat": 4,
    "nbformat_minor": 5
}

with open(path, 'w') as f:
    json.dump(nb, f, indent=1)

print(f"✅ Credit Decision Engine refined and saved at {path}")
