{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d30cccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c3d1663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and split:\n",
      "   Total samples: 30,000\n",
      "   Training set: 24,000 (80%)\n",
      "   Test set: 6,000 (20%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../3. Data/2. PD_Data/features_with_pd_predictions.csv\")\n",
    "\n",
    "feature_cols = [\n",
    "    \"avgMonthlyIncome\",\n",
    "    \"incomeCV\",\n",
    "    \"expenseRatio\",\n",
    "    \"emiRatio\",\n",
    "    \"avgMonthlyBalance\",\n",
    "    \"bounceCount\"\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Split: 80% train, 20% test\n",
    "X_train, X_test = train_test_split(\n",
    "    X, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Data loaded and split:\")\n",
    "print(f\"   Total samples: {len(df):,}\")\n",
    "print(f\"   Training set: {len(X_train):,} (80%)\")\n",
    "print(f\"   Test set: {len(X_test):,} (20%)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b56fc9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Isolation Forest...\n",
      "Model trained successfully\n",
      "   Threshold: 0.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Isolation Forest...\")\n",
    "\n",
    "# Fit scaler on training data only\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Train Isolation Forest\n",
    "iso = IsolationForest(\n",
    "    n_estimators=200,\n",
    "    contamination=0.03,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "iso.fit(X_train_scaled)\n",
    "\n",
    "# Compute threshold on training set only\n",
    "train_scores = iso.decision_function(X_train_scaled)\n",
    "threshold = np.percentile(train_scores, 3)\n",
    "\n",
    "print(f\"Model trained successfully\")\n",
    "print(f\"   Threshold: {threshold:.6f}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34fa4d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET EVALUATION:\n",
      "Normal Transactions:  23,280 (97.00%)\n",
      "Anomalies Detected:   720 (3.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING SET EVALUATION:\")\n",
    "\n",
    "train_pred = (train_scores < threshold).astype(int)\n",
    "train_anomaly_count = train_pred.sum()\n",
    "train_normal_count = len(train_pred) - train_anomaly_count\n",
    "\n",
    "print(f\"Normal Transactions:  {train_normal_count:,} ({100 * train_normal_count / len(train_pred):.2f}%)\")\n",
    "print(f\"Anomalies Detected:   {train_anomaly_count:,} ({100 * train_anomaly_count / len(train_pred):.2f}%)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19b8e2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET EVALUATION:\n",
      "Normal Transactions:  5,813 (96.88%)\n",
      "Anomalies Detected:   187 (3.12%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST SET EVALUATION:\")\n",
    "\n",
    "# Transform test data using fitted scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Get anomaly scores for test set\n",
    "test_scores = iso.decision_function(X_test_scaled)\n",
    "test_pred = (test_scores < threshold).astype(int)\n",
    "\n",
    "test_anomaly_count = test_pred.sum()\n",
    "test_normal_count = len(test_pred) - test_anomaly_count\n",
    "\n",
    "print(f\"Normal Transactions:  {test_normal_count:,} ({100 * test_normal_count / len(test_pred):.2f}%)\")\n",
    "print(f\"Anomalies Detected:   {test_anomaly_count:,} ({100 * test_anomaly_count / len(test_pred):.2f}%)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3bb5835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE DETECTED ANOMALIES (from test set):\n",
      "\n",
      "Top 5 most anomalous transactions:\n",
      "\n",
      "       avgMonthlyIncome  incomeCV  expenseRatio  emiRatio  avgMonthlyBalance  bounceCount  anomaly_score  anomalyFlag\n",
      "25687         989797.19     0.905         0.306     0.048         1038393.40            1      -0.129270            1\n",
      "25703        1048161.17     0.907         0.260     0.000         1002782.24            0      -0.121970            1\n",
      "24537         953735.53     1.167         0.366     0.059         1107671.78            0      -0.115714            1\n",
      "24799         865038.62     0.956         0.331     0.080         1032292.74            1      -0.110130            1\n",
      "24833         956519.15     1.127         0.342     0.064         1181329.98            0      -0.108054            1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SAMPLE DETECTED ANOMALIES (from test set):\")\n",
    "\n",
    "X_test_with_scores = X_test.copy()\n",
    "X_test_with_scores['anomaly_score'] = test_scores\n",
    "X_test_with_scores['anomalyFlag'] = test_pred\n",
    "\n",
    "anomalies_df = X_test_with_scores[X_test_with_scores['anomalyFlag'] == 1].sort_values('anomaly_score')\n",
    "\n",
    "if len(anomalies_df) > 0:\n",
    "    print(\"\\nTop 5 most anomalous transactions:\\n\")\n",
    "    print(anomalies_df.head(5).to_string())\n",
    "else:\n",
    "    print(\"No anomalies detected in test set\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1fbb0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(iso, '../artifacts/isolation_forest.joblib')\n",
    "joblib.dump(scaler, '../artifacts/if_scaler.joblib')\n",
    "\n",
    "print(\"Models saved successfully:\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "025ffad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying anomaly detection to full dataset...\n",
      "Full dataset with anomaly flags saved to:\n",
      "   ../../../3. Data/3. Anomaly_Data/features_with_anomaly.csv\n",
      "\n",
      "ðŸ“Š FINAL DATASET SUMMARY:\n",
      "âœ… Normal Transactions:  29,093 (96.98%)\n",
      "ðŸš¨ Anomalies Detected:   907 (3.02%)\n",
      "ðŸ“Š Total Records:        30,000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying anomaly detection to full dataset...\")\n",
    "\n",
    "X_full_scaled = scaler.transform(X)\n",
    "df['anomaly_score'] = iso.decision_function(X_full_scaled)\n",
    "df['anomalyFlag'] = (df['anomaly_score'] < threshold).astype(int)\n",
    "\n",
    "output_path =\"../../../3. Data/3. Anomaly_Data/features_with_anomaly.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Full dataset with anomaly flags saved to:\")\n",
    "print(f\"   {output_path}\")\n",
    "print()\n",
    "\n",
    "# Final summary\n",
    "final_anomaly_count = df['anomalyFlag'].sum()\n",
    "final_normal_count = len(df) - final_anomaly_count\n",
    "\n",
    "print(\"ðŸ“Š FINAL DATASET SUMMARY:\")\n",
    "print(f\"âœ… Normal Transactions:  {final_normal_count:,} ({100 * final_normal_count / len(df):.2f}%)\")\n",
    "print(f\"ðŸš¨ Anomalies Detected:   {final_anomaly_count:,} ({100 * final_anomaly_count / len(df):.2f}%)\")\n",
    "print(f\"ðŸ“Š Total Records:        {len(df):,}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45a3cbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL PERFORMANCE METRICS (Isolation Forest Validation)\n",
      "\n",
      "ðŸ“Š CORE METRICS:\n",
      "  False Positive Rate:   0.0346 (3.46%)\n",
      "  Specificity (TNR):     0.9654 (96.54%)\n",
      "\n",
      "ðŸ“‹ CONFUSION MATRIX:\n",
      "                 Predicted Normal  Predicted Anomaly\n",
      "Actual Normal          3824              137\n",
      "Actual Anomaly         1989               50\n",
      "âœ… EXCELLENT: Very low false positives (3.46%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "y_true = (\n",
    "    (X_test['expenseRatio'] > 0.85) |\n",
    "    ((X_test['incomeCV'] > 0.5) & (X_test['expenseRatio'] > 0.75)) |\n",
    "    (X_test['bounceCount'] >= 2) |\n",
    "    (X_test['emiRatio'] > 0.6)\n",
    ").astype(int)\n",
    "y_pred = test_pred\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "# -------------------------------\n",
    "# Output\n",
    "# -------------------------------\n",
    "print(\"MODEL PERFORMANCE METRICS (Isolation Forest Validation)\")\n",
    "\n",
    "print(\"\\nðŸ“Š CORE METRICS:\")\n",
    "print(f\"  False Positive Rate:   {fpr:.4f} ({fpr*100:.2f}%)\")\n",
    "print(f\"  Specificity (TNR):     {specificity:.4f} ({specificity*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nðŸ“‹ CONFUSION MATRIX:\")\n",
    "print(\"                 Predicted Normal  Predicted Anomaly\")\n",
    "print(f\"Actual Normal         {tn:5d}            {fp:5d}\")\n",
    "print(f\"Actual Anomaly        {fn:5d}            {tp:5d}\")\n",
    "\n",
    "\n",
    "if fpr < 0.05:\n",
    "    print(f\"âœ… EXCELLENT: Very low false positives ({fpr*100:.2f}%)\")\n",
    "elif fpr < 0.10:\n",
    "    print(f\"âœ… GOOD: Acceptable false positives ({fpr*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"âš ï¸  WARNING: High false positives ({fpr*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecefd47e",
   "metadata": {},
   "source": [
    "## ðŸš¨ The model demonstrates a low False Positive Rate of 3.46%, indicating that it rarely misclassifies normal customer behavior as anomalous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7012884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH PREDICTION RESULTS:\n",
      "======================================================================\n",
      " avgMonthlyIncome  expenseRatio  bounceCount  anomaly_score    status\n",
      "            50000           0.6            0       0.157587  âœ… Normal\n",
      "             8000           1.0            3      -0.007327 ðŸš¨ Anomaly\n",
      "           200000           1.0            2      -0.017572 ðŸš¨ Anomaly\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "scaler = joblib.load(\"../artifacts/if_scaler.joblib\")\n",
    "iso = joblib.load(\"../artifacts/isolation_forest.joblib\")\n",
    "train_scores = iso.decision_function(scaler.transform(X_train))\n",
    "threshold = np.percentile(train_scores, 3)\n",
    "\n",
    "# Multiple test cases\n",
    "test_cases = pd.DataFrame([\n",
    "    {'avgMonthlyIncome': 50000, 'incomeCV': 0.2, 'expenseRatio': 0.6, 'emiRatio': 0.15, 'avgMonthlyBalance': 60000, 'bounceCount': 0},\n",
    "    {'avgMonthlyIncome': 8000, 'incomeCV': 1.2, 'expenseRatio': 1, 'emiRatio': 0.5, 'avgMonthlyBalance': 10000, 'bounceCount': 3},\n",
    "    {'avgMonthlyIncome': 200000, 'incomeCV': 1.2, 'expenseRatio': 1, 'emiRatio': 1.5, 'avgMonthlyBalance': 150000, 'bounceCount': 2},\n",
    "])\n",
    "\n",
    "# Predict\n",
    "test_scaled = scaler.transform(test_cases)\n",
    "test_cases['anomaly_score'] = iso.decision_function(test_scaled)\n",
    "test_cases['anomaly_flag'] = (test_cases['anomaly_score'] < threshold).astype(int)\n",
    "test_cases['status'] = test_cases['anomaly_flag'].map({0: 'âœ… Normal', 1: 'ðŸš¨ Anomaly'})\n",
    "\n",
    "print(\"BATCH PREDICTION RESULTS:\")\n",
    "print(\"=\"*70)\n",
    "print(test_cases[['avgMonthlyIncome', 'expenseRatio', 'bounceCount', 'anomaly_score', 'status']].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
